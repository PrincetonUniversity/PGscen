{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating load scenarios using PGscen ##\n",
    "\n",
    "In this notebook we will use PGscen to create demand scenarios for the load zones in the NYISO power grid. This can also be done using the command line tool ```pgscen-ny-load``` installed as part of PGscen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-02-25'\n",
    "!pgscen-ny-load {start_date} 3 -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will go through and explain the steps carried out by the above tool in generating scenarios for a single day, as well as show some of the characteristics of the model that PGscen implements.\n",
    "\n",
    "We begin by finding the folder in which input datasets are located, and where the output scenarios will be saved. We then choose the date for which scenarios will be generated. We normalize our data to UTC time, and our scenarios start at 6am UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "start_date = '2019-05-21'\n",
    "cur_path = Path(\"nyiso_day_ahead_load.ipynb\").parent.resolve()\n",
    "data_dir = Path(cur_path, '..', \"data\", \"NYISO\").resolve()\n",
    "print(\"The data folder we will use is: {}\".format(data_dir))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "scenario_count = 1000\n",
    "scen_start_time = pd.to_datetime(' '.join([start_date, \"06:00:00\"]), utc=True)\n",
    "print(\"Scenarios will start at: {}\".format(scen_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load the actual demand observed for each load zone and the day-ahead forecasted demand. These two datasets are then split according to whether they came from before the day we want to generate scenarios for (```hist```) or during/after the scenario day (```futures```).\n",
    "\n",
    "We will use all of the historical data to train the model, and the forecasts for the scenario day to generate new scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgscen.utils.data_utils import (\n",
    "    load_ny_load_data, split_actuals_hist_future, split_forecasts_hist_future)\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "scen_timesteps = pd.date_range(start=scen_start_time, periods=24, freq='H')\n",
    "\n",
    "load_zone_actual_df, load_zone_forecast_df = load_ny_load_data()\n",
    "\n",
    "(load_zone_actual_hists,\n",
    "     load_zone_actual_futures) = split_actuals_hist_future(\n",
    "            load_zone_actual_df, scen_timesteps)\n",
    "\n",
    "(load_zone_forecast_hists,\n",
    "     load_zone_forecast_futures) = split_forecasts_hist_future(\n",
    "            load_zone_forecast_df, scen_timesteps)\n",
    "\n",
    "print(\"LOAD ACTUALS\")\n",
    "display(load_zone_actual_df.iloc[:5, :].round(1))\n",
    "print(\"\")\n",
    "print(\"LOAD FORECASTS\")\n",
    "display(load_zone_forecast_df.iloc[:5, :].round(1))\n",
    "print(\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [19, 11]\n",
    "\n",
    "fig, (hist_ax, future_ax) = plt.subplots(figsize=(17, 6),\n",
    "                                         nrows=1, ncols=2, sharey=True)\n",
    "\n",
    "title_args = dict(weight='semibold', size=27)\n",
    "actual_clr, fcst_clr = \"#430093\", \"#D9C800\"\n",
    "plt_asset = 'N.Y.C.'\n",
    "\n",
    "hist_ax.set_title(\"History\", **title_args)\n",
    "hist_ax.plot(load_zone_actual_hists[plt_asset][-800:],\n",
    "             c=actual_clr, lw=5, alpha=0.6)\n",
    "hist_ax.plot(load_zone_forecast_hists['Forecast_time'][-800:],\n",
    "             load_zone_forecast_hists[plt_asset][-800:],\n",
    "             c=fcst_clr, lw=3, alpha=0.8)\n",
    "\n",
    "future_ax.set_title(\"Future\", **title_args)\n",
    "future_ax.plot(load_zone_actual_futures[plt_asset][:250],\n",
    "               c=actual_clr, lw=5, alpha=0.6)\n",
    "future_ax.plot(load_zone_forecast_futures['Forecast_time'][:250],\n",
    "               load_zone_forecast_futures[plt_asset][:250],\n",
    "               c=fcst_clr, lw=3, alpha=0.8)\n",
    "\n",
    "future_ax.fill_between(load_zone_actual_futures.index[:24] - pd.Timedelta(hours=1),\n",
    "                       load_zone_actual_futures[plt_asset][:24].min() - 700,\n",
    "                       load_zone_actual_futures[plt_asset][:24].max() + 700,\n",
    "                       facecolor='red', edgecolor='none', alpha=0.13)\n",
    "\n",
    "for ax in [hist_ax, future_ax]:\n",
    "    ax.tick_params(which='both', labelsize=15)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "    ax.grid(linewidth=0.9, alpha=0.41)\n",
    "    ax.axhline(0, lw=1.3, c='black', alpha=1)\n",
    "    ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "\n",
    "lgnd_ptchs = [Patch(color=actual_clr, alpha=0.53, label=\"Actuals\"),\n",
    "              Patch(color=fcst_clr, alpha=0.53, label=\"Forecasts\")]\n",
    "\n",
    "_ = fig.legend(handles=lgnd_ptchs, frameon=False, fontsize=29, ncol=2, loc=8,\n",
    "               bbox_to_anchor=(0.5, -0.17), handletextpad=0.7)\n",
    "fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the historical data to train our scenario GEMINI model, which is handled by our scenario engine. This model will fit a covariance matrix for the set of assets (in this case, load zones), and another covariance matrix for the set of time points for the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgscen.engine import GeminiEngine\n",
    "\n",
    "ge = GeminiEngine(load_zone_actual_hists, load_zone_forecast_hists,\n",
    "                  scen_start_time, asset_type='load')\n",
    "ge.fit(asset_rho=0.05, horizon_rho=0.05)\n",
    "\n",
    "display(ge.model.asset_cov.round(3))\n",
    "display(ge.model.horizon_cov.iloc[:11, :11].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, for example, that using a stronger regularization penalty for our LASSO model when fitting the model results in sparser covariance matrices. These covariances can be in turn used to calculate partial correlations between each pair of assets and time points to produce graphical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from ipywidgets import interact, FloatText\n",
    "from pgscen.utils.plot_utils import get_clustermat, cov_cmap\n",
    "import networkx as nx\n",
    "from itertools import combinations as combn\n",
    "\n",
    "\n",
    "def draw_pcor_graph(pcor_mat, asset_list, ax, plt_thresh, **nxargs):\n",
    "    asset_graph = nx.Graph()\n",
    "\n",
    "    for (i, asset1), (j, asset2) in combn(enumerate(asset_list), 2):\n",
    "        if np.abs(pcor_mat[i, j]) >= plt_thresh:\n",
    "            asset_graph.add_edge(asset1, asset2, pcor=pcor_mat[i, j])\n",
    "    \n",
    "    nx.draw(asset_graph, ax=ax, with_labels=True, \n",
    "            node_color='green', font_weight='bold',\n",
    "            edge_color=[(0.10, 0.37, 1., 0.47) if val > 0 else (1., 0., 0., 0.47)\n",
    "                        for val in nx.get_edge_attributes(asset_graph, 'pcor').values()],\n",
    "            width=[53 * (val - plt_thresh)\n",
    "                   for val in nx.get_edge_attributes(asset_graph, 'pcor').values()],\n",
    "            **nxargs)\n",
    "\n",
    "def plot_zone_covars(rho):\n",
    "    ge.fit(asset_rho=rho, horizon_rho=rho)\n",
    "\n",
    "    fig, axarr = plt.subplots(figsize=(15, 12), nrows=2, ncols=2)\n",
    "    asset_clust = get_clustermat(ge.model.asset_cov)\n",
    "    asset_var = asset_clust.iloc[0, 0]\n",
    "    time_clust = get_clustermat(ge.model.horizon_cov)\n",
    "    time_var = time_clust.iloc[0, 0]\n",
    "\n",
    "    sns.heatmap(asset_clust, ax=axarr[0, 0],\n",
    "                cmap=cov_cmap, vmin=-asset_var, vmax=asset_var, square=True)\n",
    "    sns.heatmap(time_clust, ax=axarr[0, 1],\n",
    "                cmap=cov_cmap, vmin=-time_var, vmax=time_var, square=True)\n",
    "\n",
    "    asset_lbls = [asset.replace('_', ' ') for asset in asset_clust.index]\n",
    "    axarr[0, 0].set_xticklabels(asset_lbls,\n",
    "                                rotation=31, ha='right', size=17)\n",
    "    axarr[0, 0].set_yticklabels(asset_lbls, size=17)\n",
    "\n",
    "    time_lbls = [ge.scen_timesteps[int(lag.split('_')[1])].strftime(\"%H:%M\")\n",
    "                 for lag in time_clust.index]\n",
    "    axarr[0, 1].set_xticklabels(time_lbls, rotation=90, size=13)\n",
    "    axarr[0, 1].set_yticklabels(time_lbls, size=13)\n",
    "\n",
    "    axarr[0, 0].set_title(\"Load Covariance\\n\", **title_args)\n",
    "    axarr[0, 1].set_title(\"Timestep Covariance\\n\", **title_args)\n",
    "    \n",
    "    asset_prec = np.linalg.inv(ge.model.asset_cov)\n",
    "    asset_pcor = -asset_prec / np.sqrt(np.outer(np.diag(asset_prec),\n",
    "                                                np.diag(asset_prec)))\n",
    "    draw_pcor_graph(asset_pcor, ge.asset_list, axarr[1, 0], 0.05, font_size=17)\n",
    "    \n",
    "    time_lbls = [ge.scen_timesteps[int(lag.split('_')[1])].strftime(\"%H\")\n",
    "                 for lag in ge.model.horizon_cov.index]\n",
    "    time_prec = np.linalg.inv(ge.model.horizon_cov)\n",
    "    time_pcor = -time_prec / np.sqrt(np.outer(np.diag(time_prec),\n",
    "                                              np.diag(time_prec)))\n",
    "    draw_pcor_graph(time_pcor, time_lbls, axarr[1, 1], 0.2, font_size=13)\n",
    "    \n",
    "    fig.tight_layout(w_pad=7)    \n",
    "\n",
    "w = FloatText(value=0.05,\n",
    "              layout={'align_self': 'center'}, style={'description_width': 'initial'},\n",
    "              disabled=False)\n",
    "_ = interact(plot_zone_covars, rho=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this fitted model to produce scenarios. This is done by producing deviations from the forecasted data for the given day using the distributions whose parameters were determined during the fitting step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge.create_scenario(scenario_count, load_zone_forecast_futures,\n",
    "                   bin_width_ratio=0.1, min_sample_size=400)\n",
    "\n",
    "display(ge.scenarios['load']['N.Y.C.'].round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "\n",
    "\n",
    "def plot_zone_scenarios(plt_zone):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    for i in range(scenario_count):\n",
    "        plt.plot(ge.scenarios['load'].iloc[i][plt_zone],\n",
    "                 c='black', alpha=0.13, lw=0.2)\n",
    "\n",
    "    plt_fcst = ge.forecasts['load'][plt_zone]\n",
    "    plt.plot(plt_fcst, c=fcst_clr, alpha=0.47, lw=4.1)\n",
    "    plt.plot(load_zone_actual_futures.loc[plt_fcst.index, plt_zone],\n",
    "             c=actual_clr, alpha=0.47, lw=4.1)\n",
    "\n",
    "    quant_df = ge.scenarios['load'][plt_zone].quantile([0.25, 0.75])\n",
    "    ax.fill_between(quant_df.columns, quant_df.iloc[0], quant_df.iloc[1],\n",
    "                    color='red', alpha=0.31)\n",
    "\n",
    "    ax.tick_params(which='both', labelsize=15)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %Hh'))\n",
    "    ax.grid(linewidth=0.9, alpha=0.41)\n",
    "    ax.axhline(0, lw=1.3, c='black', alpha=1)\n",
    "    ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "    \n",
    "    lgnd_ptchs = [Patch(color='black', alpha=0.23, label=\"Scenarios\"),\n",
    "                  Patch(color='red', alpha=0.41, label=\"Interquartile Range\"),\n",
    "                  Patch(color=fcst_clr, alpha=0.81, label=\"Forecast\"),\n",
    "                  Patch(color=actual_clr, alpha=0.81, label=\"Actual\")]\n",
    "\n",
    "    _ = plt.legend(handles=lgnd_ptchs, frameon=False, fontsize=17, ncol=4, loc=8,\n",
    "                   bbox_to_anchor=(0.5, -0.17), handletextpad=0.7)\n",
    "\n",
    "w = Dropdown(options=ge.asset_list, description=\"Scenarios for zone:\",\n",
    "             layout={'align_self': 'center'}, style={'description_width': 'initial'},\n",
    "             disabled=False)\n",
    "_ = interact(plot_zone_scenarios, plt_zone=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final step is to save the generated scenarios to file. We include the actual and forecasted load demands in the saved data to facilitate downstream analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge.write_to_csv(data_dir, load_zone_actual_futures, write_forecasts=True)\n",
    "!ls {data_dir}/{start_date.replace('-', '')}/load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
